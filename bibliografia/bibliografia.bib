%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFÍA                                                                 %
%                                                                              %
% Objetivo: Recopilar las referencias a información utilizadas y/o algunas     %
%           otras que puedan resultar interesantes                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{wolterink2021implicit,
  title={Implicit Neural Representations for Deformable Image Registration},
  author={Wolterink, Jelmer M and Zwienenberg, Jesse C and Brune, Christoph},
  booktitle={Medical Imaging with Deep Learning 2022},
  year={2022}
}

@article{FIRE, 
title={FIRE: Fundus Image Registration dataset}, 
volume={1},
url={https://www.maio-journal.com/index.php/MAIO/article/view/42},
DOI={10.35119/maio.v1i4.42}, 
abstractNote={&amp;lt;p&amp;gt;Purpose:Retinal image registration is a useful tool for medical professionals. However, performance evaluation of registration methods has not been consistently assessed in the literature. To address that, a dataset comprised of retinal image pairs annotated with ground truth and an evaluation protocol for registration methods is proposed.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Methods: The dataset is comprised by 134 retinal fundus image pairs. These pairs are classified into three categories, according to characteristics that are relevant to indicative registration applications. Such characteristics are the degree of overlap between images and the presence/absence of anatomical differences. Ground truth in the form of corresponding image points and a protocol to evaluate registration performance are provided.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Results: The proposed protocol is shown to enable quantitative and comparative evaluation of retinal registration methods under a variety of conditions.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;Conclusion: This work enables the fair comparison of retinal registration methods. It also helps researchers to select the registration method that is most appropriate given a specific target use.&amp;lt;/p&amp;gt;}, number={4}, journal={Modeling and Artificial Intelligence in Ophthalmology}, author={Hernandez-Matas, Carlos and Zabulis, Xenophon and Triantafyllou, Areti and Anyfanti, Panagiota and Douma, Stella and Argyros, Antonis A},
year={2017}, 
month={Jul.},
pages={16–28}
}

@misc{molaei2023implicitneuralrepresentationmedical,
      title={Implicit Neural Representation in Medical Imaging: A Comparative Survey}, 
      author={Amirali Molaei and Amirhossein Aminimehr and Armin Tavakoli and Amirhossein Kazerouni and Bobby Azad and Reza Azad and Dorit Merhof},
      year={2023},
      eprint={2307.16142},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2307.16142}, 
}

@Article{RFMiD,
AUTHOR = {Pachade, Samiksha and Porwal, Prasanna and Thulkar, Dhanshree and Kokare, Manesh and Deshmukh, Girish and Sahasrabuddhe, Vivek and Giancardo, Luca and Quellec, Gwenolé and Mériaudeau, Fabrice},
TITLE = {Retinal Fundus Multi-Disease Image Dataset (RFMiD): A Dataset for Multi-Disease Detection Research},
JOURNAL = {Data},
VOLUME = {6},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/2306-5729/6/2/14},
ISSN = {2306-5729},
ABSTRACT = {The world faces difficulties in terms of eye care, including treatment, quality of prevention, vision rehabilitation services, and scarcity of trained eye care experts. Early detection and diagnosis of ocular pathologies would enable forestall of visual impairment. One challenge that limits the adoption of computer-aided diagnosis tool by ophthalmologists is the number of sight-threatening rare pathologies, such as central retinal artery occlusion or anterior ischemic optic neuropathy, and others are usually ignored. In the past two decades, many publicly available datasets of color fundus images have been collected with a primary focus on diabetic retinopathy, glaucoma, age-related macular degeneration and few other frequent pathologies. To enable development of methods for automatic ocular disease classification of frequent diseases along with the rare pathologies, we have created a new Retinal Fundus Multi-disease Image Dataset (RFMiD). It consists of 3200 fundus images captured using three different fundus cameras with 46 conditions annotated through adjudicated consensus of two senior retinal experts. To the best of our knowledge, our dataset, RFMiD, is the only publicly available dataset that constitutes such a wide variety of diseases that appear in routine clinical settings. This dataset will enable the development of generalizable models for retinal screening.},
DOI = {10.3390/data6020014}
}

@misc{bharati2022deeplearningmedicalimage,
      title={Deep Learning for Medical Image Registration: A Comprehensive Review}, 
      author={Subrato Bharati and M. Rubaiyat Hossain Mondal and Prajoy Podder and V. B. Surya Prasath},
      year={2022},
      eprint={2204.11341},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2204.11341}, 
}

@book{goshtasby2017theory,
  title={Theory and applications of image registration},
  author={Goshtasby, Arthur Ardeshir},
  year={2017},
  publisher={John Wiley \& Sons}
}

@misc{sitzmann2020implicitneuralrepresentationsperiodic,
      title={Implicit Neural Representations with Periodic Activation Functions}, 
      author={Vincent Sitzmann and Julien N. P. Martel and Alexander W. Bergman and David B. Lindell and Gordon Wetzstein},
      year={2020},
      eprint={2006.09661},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2006.09661}, 
}

@misc{mildenhall2020nerfrepresentingscenesneural,
      title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis}, 
      author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
      year={2020},
      eprint={2003.08934},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2003.08934}, 
}


@article{HyperelasticRegularization,
author = {Burger, Martin and Modersitzki, Jan and Ruthotto, Lars},
title = {A Hyperelastic Regularization Energy for Image Registration},
journal = {SIAM Journal on Scientific Computing},
volume = {35},
number = {1},
pages = {B132-B148},
year = {2013},
doi = {10.1137/110835955},
URL = { https://doi.org/10.1137/110835955},
eprint = { https://doi.org/10.1137/110835955},
abstract = { Image registration is one of the most challenging problems in image processing, where ill-posedness arises due to noisy data as well as nonuniqueness, and hence the choice of regularization is crucial. This paper presents hyperelasticity as a regularizer and introduces a new and stable numerical implementation. On one hand, hyperelastic registration is an appropriate model for large and highly nonlinear deformations, for which a linear elastic model needs to fail. On the other hand, the hyperelastic regularizer yields very regular and diffeomorphic transformations. While hyperelasticity might be considered as just an additional outstanding regularization option for some applications, it becomes inevitable for applications involving higher order distance measures like mass-preserving registration. The paper gives a short introduction to image registration and hyperelasticity. The hyperelastic image registration problem is phrased in a variational setting, and an existence proof is provided. The focus of the paper, however, is on a robust numerical scheme. A key challenge is an unbiased discretization of hyperelasticity, which enables the numerical monitoring of variations of length, surface, and volume of infinitesimal reference elements. We resolve this issue by using a nodal-based discretization with a special tetrahedral partitioning. The potential of the hyperelastic registration is demonstrated in a direct comparison with a linear elastic registration in an academic example. The paper also presents a real life application from three-dimensional positron emission tomography of the human heart which requires mass preservation, and thus hyperelastic registration is the only option. }
}

@misc{sun2024medicalimageregistrationneural,
      title={Medical Image Registration via Neural Fields}, 
      author={Shanlin Sun and Kun Han and Chenyu You and Hao Tang and Deying Kong and Junayed Naushad and Xiangyi Yan and Haoyu Ma and Pooya Khosravi and James S. Duncan and Xiaohui Xie},
      year={2024},
      eprint={2206.03111},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2206.03111}, 
}

@article{nodeo,
  author       = {Yifan Wu and
                  Tom Z. Jiahao and
                  Jiancong Wang and
                  Paul A. Yushkevich and
                  James C. Gee and
                  M. Ani Hsieh},
  title        = {Deformable Image Registration using Neural ODEs},
  journal      = {CoRR},
  volume       = {abs/2108.03443},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.03443},
  eprinttype    = {arXiv},
  eprint       = {2108.03443},
  timestamp    = {Wed, 11 Aug 2021 15:24:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-03443.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{neuralode,
  author       = {Tian Qi Chen and
                  Yulia Rubanova and
                  Jesse Bettencourt and
                  David Duvenaud},
  title        = {Neural Ordinary Differential Equations},
  journal      = {CoRR},
  volume       = {abs/1806.07366},
  year         = {2018},
  url          = {http://arxiv.org/abs/1806.07366},
  eprinttype    = {arXiv},
  eprint       = {1806.07366},
  timestamp    = {Mon, 22 Jul 2019 14:09:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1806-07366.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{bigwarp,
  author={Bogovic, John A. and Hanslovsky, Philipp and Wong, Allan and Saalfeld, Stephan},
  booktitle={2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Robust registration of calcium images by learned contrast synthesis}, 
  year={2016},
  volume={},
  number={},
  pages={1123-1126},
  keywords={Radio frequency;Cost function;Imaging;Training;Calcium;Neurons;Image registration;Image Registration;Machine Learning},
  doi={10.1109/ISBI.2016.7493463}}

@article{deeplernreview3dreg,
author = {Xiao, Haonan and Teng, Xinzhi and Liu, Chenyang and Li, Tian and Ren, Ge and Yang, Ruijie and Shen, Dinggang and Cai, Jing},
year = {2021},
month = {12},
pages = {},
title = {A review of deep learning-based three-dimensional medical image registration methods},
volume = {11},
journal = {Quantitative Imaging in Medicine and Surgery},
doi = {10.21037/qims-21-175}
}

@misc{scopus,
  title        = {Scopus},
  howpublished = {Retrieved from https://www.scopus.com/},
  note         = {Accessed on 10-12-2024},
  year         = {2024}
}

@ARTICLE{medicalimageanalysis,
  author={Altaf, Fouzia and Islam, Syed M. S. and Akhtar, Naveed and Janjua, Naeem Khalid},
  journal={IEEE Access}, 
  title={Going Deep in Medical Image Analysis: Concepts, Methods, Challenges, and Future Directions}, 
  year={2019},
  volume={7},
  number={},
  pages={99540-99572},
  keywords={Biomedical imaging;Deep learning;Computational modeling;Task analysis;Computer vision;Data models;Deep learning;medical imaging;artificial neural networks;survey;tutorial;data sets},
  doi={10.1109/ACCESS.2019.2929365}
}

@misc{shen2023nerpimplicitneuralrepresentation,
      title={NeRP: Implicit Neural Representation Learning with Prior Embedding for Sparsely Sampled Image Reconstruction}, 
      author={Liyue Shen and John Pauly and Lei Xing},
      year={2023},
      eprint={2108.10991},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2108.10991}, 
}

@misc{rahaman2019spectralbiasneuralnetworks,
      title={On the Spectral Bias of Neural Networks}, 
      author={Nasim Rahaman and Aristide Baratin and Devansh Arpit and Felix Draxler and Min Lin and Fred A. Hamprecht and Yoshua Bengio and Aaron Courville},
      year={2019},
      eprint={1806.08734},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1806.08734}, 
}

@INPROCEEDINGS{inrrobots,
  author={Schmidt, Adam and Mohareri, Omid and DiMaio, Simon and Salcudean, Septimiu E.},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)}, 
  title={Fast Graph Refinement and Implicit Neural Representation for Tissue Tracking}, 
  year={2022},
  volume={},
  number={},
  pages={1281-1288},
  keywords={Deformable models;Interpolation;Image resolution;Automation;Tracking;Force;Surgery},
  doi={10.1109/ICRA46639.2022.9811742}
}

@INPROCEEDINGS{teleoperatdrob,
  author={Zhang, Heng and Zhu, Lifeng and Shen, Jiangwei and Song, Aiguo},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Implicit Neural Field Guidance for Teleoperated Robot-assisted Surgery}, 
  year={2023},
  volume={},
  number={},
  pages={6866-6872},
  keywords={Training;Medical robotics;Neural networks;Surgery;Phantoms;Mouth;Trajectory},
  doi={10.1109/ICRA48891.2023.10160475}
  }



@misc{yu2024neuraltrajectorymodelimplicit,
      title={Neural Trajectory Model: Implicit Neural Trajectory Representation for Trajectories Generation}, 
      author={Zihan Yu and Yuqing Tang},
      year={2024},
      eprint={2402.01254},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2402.01254}, 
}

@INPROCEEDINGS{trajectinr,
  author={Tenzer, Mark and Tung, Emmanuel and Rasheed, Zeeshan and Shafique, Khurram},
  booktitle={2024 25th IEEE International Conference on Mobile Data Management (MDM)}, 
  title={Generating Trajectories from Implicit Neural Models}, 
  year={2024},
  volume={},
  number={},
  pages={129-138},
  keywords={Training;Roads;Image edge detection;Stochastic processes;Routing;Prediction algorithms;Data models;trajectory generation;implicit neural representation;deep learning;unsupervised learning},
  doi={10.1109/MDM61037.2024.00036}}


@misc{essakine2024standimplicitneuralrepresentations,
      title={Where Do We Stand with Implicit Neural Representations? A Technical and Performance Survey}, 
      author={Amer Essakine and Yanqi Cheng and Chun-Wun Cheng and Lipei Zhang and Zhongying Deng and Lei Zhu and Carola-Bibiane Schönlieb and Angelica I Aviles-Rivero},
      year={2024},
      eprint={2411.03688},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.03688}, 
}

@misc{ramasinghe2022periodicityunifyingframeworkactivations,
      title={Beyond Periodicity: Towards a Unifying Framework for Activations in Coordinate-MLPs}, 
      author={Sameera Ramasinghe and Simon Lucey},
      year={2022},
      eprint={2111.15135},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2111.15135}, 
}

@misc{saragadam2023wirewaveletimplicitneural,
      title={WIRE: Wavelet Implicit Neural Representations}, 
      author={Vishwanath Saragadam and Daniel LeJeune and Jasper Tan and Guha Balakrishnan and Ashok Veeraraghavan and Richard G. Baraniuk},
      year={2023},
      eprint={2301.05187},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.05187}, 
}

@misc{reddy2022multiimplicitneuralrepresentationfonts,
      title={A Multi-Implicit Neural Representation for Fonts}, 
      author={Pradyumna Reddy and Zhifei Zhang and Matthew Fisher and Hailin Jin and Zhaowen Wang and Niloy J. Mitra},
      year={2022},
      eprint={2106.06866},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2106.06866}, 
}

@misc{wu2021iremhighresolutionmagneticresonance,
      title={IREM: High-Resolution Magnetic Resonance (MR) Image Reconstruction via Implicit Neural Representation}, 
      author={Qing Wu and Yuwei Li and Lan Xu and Ruiming Feng and Hongjiang Wei and Qing Yang and Boliang Yu and Xiaozhao Liu and Jingyi Yu and Yuyao Zhang},
      year={2021},
      eprint={2106.15097},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2106.15097}, 
}

@misc{mescheder2019occupancynetworkslearning3d,
      title={Occupancy Networks: Learning 3D Reconstruction in Function Space}, 
      author={Lars Mescheder and Michael Oechsle and Michael Niemeyer and Sebastian Nowozin and Andreas Geiger},
      year={2019},
      eprint={1812.03828},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1812.03828}, 
}

@article{Balakrishnan_2019voxelmorph,
   title={VoxelMorph: A Learning Framework for Deformable Medical Image Registration},
   volume={38},
   ISSN={1558-254X},
   url={http://dx.doi.org/10.1109/TMI.2019.2897538},
   DOI={10.1109/tmi.2019.2897538},
   number={8},
   journal={IEEE Transactions on Medical Imaging},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R. and Guttag, John and Dalca, Adrian V.},
   year={2019},
   month=aug, pages={1788–1800}
}

@misc{li2024neuralgraphicsprimitivesdeformable,
      title={Neural Graphics Primitives-based Deformable Image Registration for On-the-fly Motion Extraction}, 
      author={Xia Li and Fabian Zhang and Muheng Li and Damien Weber and Antony Lomax and Joachim Buhmann and Ye Zhang},
      year={2024},
      eprint={2402.05568},
      archivePrefix={arXiv},
      primaryClass={physics.med-ph},
      url={https://arxiv.org/abs/2402.05568}, 
}

@misc{wang2022neuralrenderingstereo3d,
      title={Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery}, 
      author={Yuehao Wang and Yonghao Long and Siu Hin Fan and Qi Dou},
      year={2022},
      eprint={2206.15255},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2206.15255}, 
}

@misc{han2022diffeomorphicimageregistrationneural,
      title={Diffeomorphic Image Registration with Neural Velocity Field}, 
      author={Kun Han and Shanlin sun and Xiangyi Yan and Chenyu You and Hao Tang and Junayed Naushad and Haoyu Ma and Deying Kong and Xiaohui Xie},
      year={2022},
      eprint={2202.12498},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2202.12498}, 
}

@misc{velikova2024implicitneuralrepresentationsbreathingcompensated,
      title={Implicit Neural Representations for Breathing-compensated Volume Reconstruction in Robotic Ultrasound}, 
      author={Yordanka Velikova and Mohammad Farid Azampour and Walter Simson and Marco Esposito and Nassir Navab},
      year={2024},
      eprint={2311.04999},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2311.04999}, 
}
@article{mueller2022instant,
    author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    journal = {ACM Trans. Graph.},
    issue_date = {July 2022},
    volume = {41},
    number = {4},
    month = jul,
    year = {2022},
    pages = {102:1--102:15},
    articleno = {102},
    numpages = {15},
    url = {https://doi.org/10.1145/3528223.3530127},
    doi = {10.1145/3528223.3530127},
    publisher = {ACM},
    address = {New York, NY, USA}
}

@misc{jacobsen2018irevnetdeepinvertiblenetworks,
      title={i-RevNet: Deep Invertible Networks}, 
      author={Jörn-Henrik Jacobsen and Arnold Smeulders and Edouard Oyallon},
      year={2018},
      eprint={1802.07088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1802.07088}, 
}