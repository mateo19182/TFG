%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFÍA                                                                 %
%                                                                              %
% Objetivo: Recopilar las referencias a información utilizadas y/o algunas     %
%           otras que puedan resultar interesantes                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{wolterink2021implicit,
  title         = {Implicit Neural Representations for Deformable Image Registration},
  author        = {Wolterink, Jelmer M and Zwienenberg, Jesse C and Brune, Christoph},
  booktitle     = {Medical Imaging with Deep Learning 2022},
  year          = {2022}
}
@article{FIRE,
  title         = {FIRE: Fundus Image Registration dataset},
  volume        = {1},
  url           = {https://www.maio-journal.com/index.php/MAIO/article/view/42},
  doi           = {10.35119/maio.v1i4.42},
  abstractnote  = {\&amp;lt;p\&amp;gt;Purpose:Retinal image registration is a useful tool for medical professionals. However, performance evaluation of registration methods has not been consistently assessed in the literature. To address that, a dataset comprised of retinal image pairs annotated with ground truth and an evaluation protocol for registration methods is proposed.\&amp;lt;/p\&amp;gt;\&amp;lt;p\&amp;gt;Methods:~The dataset is comprised by 134 retinal fundus image pairs. These pairs are classified into three categories, according to characteristics that are relevant to indicative registration applications. Such characteristics are the degree of overlap between images and the presence/absence of anatomical differences. Ground truth in the form of corresponding image points and a protocol to evaluate registration performance are provided.\&amp;lt;/p\&amp;gt;\&amp;lt;p\&amp;gt;Results:~The proposed protocol is shown to enable quantitative and comparative evaluation of retinal registration methods under a variety of conditions.\&amp;lt;/p\&amp;gt;\&amp;lt;p\&amp;gt;Conclusion:~This work enables the fair comparison of retinal registration methods. It also helps researchers to select the registration method that is most appropriate given a specific target use.\&amp;lt;/p\&amp;gt;},
  number        = {4},
  journal       = {Modeling and Artificial Intelligence in Ophthalmology},
  author        = {Hernandez-Matas, Carlos and Zabulis, Xenophon and Triantafyllou, Areti and Anyfanti, Panagiota and Douma, Stella and Argyros, Antonis A},
  year          = {2017},
  month         = {Jul.},
  pages         = {16–28}
}
@misc{molaei2023implicitneuralrepresentationmedical,
  title         = {Implicit Neural Representation in Medical Imaging: A Comparative Survey},
  author        = {Amirali Molaei and Amirhossein Aminimehr and Armin Tavakoli and Amirhossein Kazerouni and Bobby Azad and Reza Azad and Dorit Merhof},
  year          = {2023},
  eprint        = {2307.16142},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2307.16142}
}
@misc{nie2024medicalimageregistrationapplication,
  title         = {Medical Image Registration and Its Application in Retinal Images: A Review},
  author        = {Qiushi Nie and Xiaoqing Zhang and Yan Hu and Mingdao Gong and Jiang Liu},
  year          = {2024},
  eprint        = {2403.16502},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2403.16502}
}
@article{RFMiD,
  author        = {Pachade, Samiksha and Porwal, Prasanna and Thulkar, Dhanshree and Kokare, Manesh and Deshmukh, Girish and Sahasrabuddhe, Vivek and Giancardo, Luca and Quellec, Gwenol\'{e} and M\'{e}riaudeau, Fabrice},
  title         = {Retinal Fundus Multi-Disease Image Dataset (RFMiD): A Dataset for Multi-Disease Detection Research},
  journal       = {Data},
  volume        = {6},
  year          = {2021},
  number        = {2},
  article-number = {14},
  url           = {https://www.mdpi.com/2306-5729/6/2/14},
  issn          = {2306-5729},
  abstract      = {The world faces difficulties in terms of eye care, including treatment, quality of prevention, vision rehabilitation services, and scarcity of trained eye care experts. Early detection and diagnosis of ocular pathologies would enable forestall of visual impairment. One challenge that limits the adoption of computer-aided diagnosis tool by ophthalmologists is the number of sight-threatening rare pathologies, such as central retinal artery occlusion or anterior ischemic optic neuropathy, and others are usually ignored. In the past two decades, many publicly available datasets of color fundus images have been collected with a primary focus on diabetic retinopathy, glaucoma, age-related macular degeneration and few other frequent pathologies. To enable development of methods for automatic ocular disease classification of frequent diseases along with the rare pathologies, we have created a new Retinal Fundus Multi-disease Image Dataset (RFMiD). It consists of 3200 fundus images captured using three different fundus cameras with 46 conditions annotated through adjudicated consensus of two senior retinal experts. To the best of our knowledge, our dataset, RFMiD, is the only publicly available dataset that constitutes such a wide variety of diseases that appear in routine clinical settings. This dataset will enable the development of generalizable models for retinal screening.},
  doi           = {10.3390/data6020014}
}
@misc{bharati2022deeplearningmedicalimage,
  title         = {Deep Learning for Medical Image Registration: A Comprehensive Review},
  author        = {Subrato Bharati and M. Rubaiyat Hossain Mondal and Prajoy Podder and V. B. Surya Prasath},
  year          = {2022},
  eprint        = {2204.11341},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2204.11341}
}
@book{goshtasby2017theory,
  title         = {Theory and applications of image registration},
  author        = {Goshtasby, Arthur Ardeshir},
  year          = {2017},
  publisher     = {John Wiley \& Sons}
}
@misc{sitzmann2020implicitneuralrepresentationsperiodic,
  title         = {Implicit Neural Representations with Periodic Activation Functions},
  author        = {Vincent Sitzmann and Julien N. P. Martel and Alexander W. Bergman and David B. Lindell and Gordon Wetzstein},
  year          = {2020},
  eprint        = {2006.09661},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2006.09661}
}
@misc{mildenhall2020nerfrepresentingscenesneural,
  title         = {NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author        = {Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  year          = {2020},
  eprint        = {2003.08934},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2003.08934}
}
@article{HyperelasticRegularization,
  author        = {Burger, Martin and Modersitzki, Jan and Ruthotto, Lars},
  title         = {A Hyperelastic Regularization Energy for Image Registration},
  journal       = {SIAM Journal on Scientific Computing},
  volume        = {35},
  number        = {1},
  pages         = {B132-B148},
  year          = {2013},
  doi           = {10.1137/110835955},
  url           = {https://doi.org/10.1137/110835955},
  eprint        = {https://doi.org/10.1137/110835955},
  abstract      = {Image registration is one of the most challenging problems in image processing, where ill-posedness arises due to noisy data as well as nonuniqueness, and hence the choice of regularization is crucial. This paper presents hyperelasticity as a regularizer and introduces a new and stable numerical implementation. On one hand, hyperelastic registration is an appropriate model for large and highly nonlinear deformations, for which a linear elastic model needs to fail. On the other hand, the hyperelastic regularizer yields very regular and diffeomorphic transformations. While hyperelasticity might be considered as just an additional outstanding regularization option for some applications, it becomes inevitable for applications involving higher order distance measures like mass-preserving registration. The paper gives a short introduction to image registration and hyperelasticity. The hyperelastic image registration problem is phrased in a variational setting, and an existence proof is provided. The focus of the paper, however, is on a robust numerical scheme. A key challenge is an unbiased discretization of hyperelasticity, which enables the numerical monitoring of variations of length, surface, and volume of infinitesimal reference elements. We resolve this issue by using a nodal-based discretization with a special tetrahedral partitioning. The potential of the hyperelastic registration is demonstrated in a direct comparison with a linear elastic registration in an academic example. The paper also presents a real life application from three-dimensional positron emission tomography of the human heart which requires mass preservation, and thus hyperelastic registration is the only option.}
}
@article{bendingenergy,
  author        = {Rueckert, D. and Sonoda, Luke and Hayes, C. and Hill, Derek and Leach, M.O. and Hawkes, D.J.},
  year          = {1999},
  month         = {09},
  pages         = {712--721},
  title         = {Nonrigid Registration Using Free-Form Deformations: Application to Breast MR Images},
  volume        = {18},
  journal       = {Medical Imaging, IEEE Transactions on},
  doi           = {10.1109/42.796284}
}
@misc{sun2024medicalimageregistrationneural,
  title         = {Medical Image Registration via Neural Fields},
  author        = {Shanlin Sun and Kun Han and Chenyu You and Hao Tang and Deying Kong and Junayed Naushad and Xiangyi Yan and Haoyu Ma and Pooya Khosravi and James S. Duncan and Xiaohui Xie},
  year          = {2024},
  eprint        = {2206.03111},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2206.03111}
}
@article{HORNIK1989359,
  title         = {Multilayer feedforward networks are universal approximators},
  journal       = {Neural Networks},
  volume        = {2},
  number        = {5},
  pages         = {359--366},
  year          = {1989},
  issn          = {0893-6080},
  doi           = {https://doi.org/10.1016/0893-6080(89)90020-8},
  url           = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
  author        = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
  keywords      = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
  abstract      = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}
@article{nodeo,
  author        = {Yifan Wu and Tom Z. Jiahao and Jiancong Wang and Paul A. Yushkevich and James C. Gee and M. Ani Hsieh},
  title         = {Deformable Image Registration using Neural ODEs},
  journal       = {CoRR},
  volume        = {abs/2108.03443},
  year          = {2021},
  url           = {https://arxiv.org/abs/2108.03443},
  eprinttype    = {arXiv},
  eprint        = {2108.03443},
  timestamp     = {Wed, 11 Aug 2021 15:24:08 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2108-03443.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{neuralode,
  author        = {Tian Qi Chen and Yulia Rubanova and Jesse Bettencourt and David Duvenaud},
  title         = {Neural Ordinary Differential Equations},
  journal       = {CoRR},
  volume        = {abs/1806.07366},
  year          = {2018},
  url           = {http://arxiv.org/abs/1806.07366},
  eprinttype    = {arXiv},
  eprint        = {1806.07366},
  timestamp     = {Mon, 22 Jul 2019 14:09:23 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1806-07366.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{bigwarp,
  author        = {Bogovic, John A. and Hanslovsky, Philipp and Wong, Allan and Saalfeld, Stephan},
  booktitle     = {2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)},
  title         = {Robust registration of calcium images by learned contrast synthesis},
  year          = {2016},
  volume        = {},
  number        = {},
  pages         = {1123--1126},
  keywords      = {Radio frequency;Cost function;Imaging;Training;Calcium;Neurons;Image registration;Image Registration;Machine Learning},
  doi           = {10.1109/ISBI.2016.7493463}
}
@incollection{eyeanat,
  title         = {Chapter 1 - Anatomy of the eye and orbit},
  editor        = {John V. Forrester and Andrew D. Dick and Paul G. McMenamin and Fiona Roberts and Eric Pearlman},
  booktitle     = {The Eye (Fourth Edition)},
  publisher     = {W.B. Saunders},
  edition       = {4th Edition},
  pages         = {1--102.e2},
  year          = {2016},
  isbn          = {978-0-7020-5554-6},
  doi           = {https://doi.org/10.1016/B978-0-7020-5554-6.00001-0},
  url           = {https://www.sciencedirect.com/science/article/pii/B9780702055546000010},
  author        = {John V. Forrester and Andrew D. Dick and Paul G. McMenamin and Fiona Roberts and Eric Pearlman}
}
@incollection{eyefunct,
  title         = {Chapter 5 - Physiology of vision and the visual system},
  editor        = {John V. Forrester and Andrew D. Dick and Paul G. McMenamin and Fiona Roberts and Eric Pearlman},
  booktitle     = {The Eye (Fourth Edition)},
  publisher     = {W.B. Saunders},
  edition       = {4th Edition},
  pages         = {269--337.e2},
  year          = {2016},
  isbn          = {978-0-7020-5554-6},
  doi           = {https://doi.org/10.1016/B978-0-7020-5554-6.00005-8},
  url           = {https://www.sciencedirect.com/science/article/pii/B9780702055546000058},
  author        = {John V. Forrester and Andrew D. Dick and Paul G. McMenamin and Fiona Roberts and Eric Pearlman}
}
@article{importglaucoma,
  author        = {Norma Herrera Hern\'{a}ndez y Jamilet Navarro Viv\'{o} y Alina Honan Gonz\'{a}lez y Belkis Ortega Ruiz},
  title         = {Importancia del diagn\'{o}stico precoz del Glaucoma.},
  journal       = {Revista M\'{e}dica Electr\'{o}nica},
  volume        = {28},
  number        = {1},
  year          = {2014},
  keywords      = {GLAUCOMA; PRESI\'{O}N INTRAOCULAR; GONIOSCOP\'{I}A; TONOMETR\'{I}A OCULAR; OFTALMOSCOP\'{I}A; HUMANO; ADULTO},
  abstract      = {Se expone al resultado de 100 pacientes estudiados (200 ojos) que asistieron a la consulta externa de Oftalmolog\'{\i}a del Hospital Universitario Faustino P\'{e}rez de Matanzas de enero del 2004 a marzo del 2005 los cuales refer\'{\i}an: cefalea, visi\'{o}n de halos de colores, cambios frecuentes de espejuelos, disminuci\'{o}n de la agudeza visual, algunos no presentaban s\'{\i}ntomas sujetivos, pero se les detect\'{o} alteraci\'{o}n de la relaci\'{o}n copa/Disco en el fondo de ojo y otros elevaci\'{o}n del tono ocular, por lo que se incluyeron en el estudio. Se les realiz\'{o} a todos los pacientes toma de agudeza visual con optotipo de Snellen y optometr\'{\i}a, examen con l\'{a}mpara de hendidura gonioscop\'{\i}a, oftalmoscop\'{\i}a directa, tonometr\'{\i}a, campo visual y curva tonom\'{e}trica. Predomin\'{o} el glaucoma cr\'{o}nico simple de \'{a}ngulo abierto presentando alteraci\'{o}n copa disco tonometr\'{\i}a de m\'{a}s de 25 mil\'{\i}metros de mercurio y defectos campim\'{e}tricos t\'{\i}picos el 57 \% de los pacientes. Se actualiz\'{o} el tratamiento m\'{e}dico de esta entidad. Se recomienda la utilizaci\'{o}n de betabloqueadores como f\'{a}rmaco inicial como segunda opci\'{o}n mi\'{o}tico pilocarpina al 2 \%, y inhibidores de la anhidraza carb\'{o}nica, agonista adren\'{e}rgicos y cirug\'{\i}a invasiva o no.},
  issn          = {1684-1824},
  pages         = {34--37},
  url           = {https://revmedicaelectronica.sld.cu/index.php/rme/article/view/259}
}
@book{kanski2011clinical,
  title         = {Clinical ophthalmology: a systematic approach},
  author        = {Kanski, Jack J and Bowling, Brad},
  year          = {2011},
  publisher     = {Elsevier Health Sciences}
}
@article{retinimaging,
  title         = {Advanced retinal imaging and applications for clinical practice: A consensus review},
  journal       = {Survey of Ophthalmology},
  volume        = {67},
  number        = {5},
  pages         = {1373--1390},
  year          = {2022},
  issn          = {0039-6257},
  doi           = {https://doi.org/10.1016/j.survophthal.2022.02.004},
  url           = {https://www.sciencedirect.com/science/article/pii/S0039625722000352},
  author        = {Meira Fogel-Levin and SriniVas R. Sadda and Philip J. Rosenfeld and Nadia Waheed and Giuseppe Querques and Bailey K Freund and David Sarraf},
  keywords      = {Color fundus photography, Widefield imaging, Fundus autofluorescence, Near infrared reflectance, Optical coherence tomography angiography, En-face optical coherence tomography, Multimodal approach},
  abstract      = {Imaging is an integral part of the evaluation and management of retinal disorders. Each imaging modality has its own unique capabilities and can show a different aspect or perspective of disease. Multimodal retinal imaging provides a wealth of substantive and insightful information; however, the integration of all this complex data can be overwhelming. We discuss the applications and the strengths and limitations of the many different retinal imaging tools that are approved for clinical use. These modalities include color fundus photography, widefield imaging, fundus autofluorescence, near infrared reflectance, optical coherence tomography angiography, and en face optical coherence tomography. We also cover the advantages and disadvantages of a multimodal approach.}
}
@article{semanticsimilarity,
  title         = {Semantic similarity metrics for image registration},
  journal       = {Medical Image Analysis},
  volume        = {87},
  pages         = {102830},
  year          = {2023},
  issn          = {1361-8415},
  doi           = {https://doi.org/10.1016/j.media.2023.102830},
  url           = {https://www.sciencedirect.com/science/article/pii/S1361841523000907},
  author        = {Steffen Czolbe and Paraskevas Pegios and Oswin Krause and Aasa Feragen},
  keywords      = {Image registration, Deep learning, Representation learning},
  abstract      = {Image registration aims to find geometric transformations that align images. Most algorithmic and deep learning-based methods solve the registration problem by minimizing a loss function, consisting of a similarity metric comparing the aligned images, and a regularization term ensuring smoothness of the transformation. Existing similarity metrics like Euclidean Distance or Normalized Cross-Correlation focus on aligning pixel intensity values or correlations, giving difficulties with low intensity contrast, noise, and ambiguous matching. We propose a semantic similarity metric for image registration, focusing on aligning image areas based on semantic correspondence instead. Our approach learns dataset-specific features that drive the optimization of a learning-based registration model. We train both an unsupervised approach extracting features with an auto-encoder, and a semi-supervised approach using supplemental segmentation data. We validate the semantic similarity metric using both deep-learning-based and algorithmic image registration methods. Compared to existing methods across four different image modalities and applications, the method achieves consistently high registration accuracy and smooth transformation fields.}
}
@misc{superpoint,
  title         = {SuperPoint: Self-Supervised Interest Point Detection and Description},
  author        = {Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
  year          = {2018},
  eprint        = {1712.07629},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1712.07629}
}
@misc{superglue,
  title         = {SuperGlue: Learning Feature Matching with Graph Neural Networks},
  author        = {Paul-Edouard Sarlin and Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
  year          = {2020},
  eprint        = {1911.11763},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1911.11763}
}
@article{Jena_2025,
  title         = {Deep implicit optimization enables robust learnable features for deformable image registration},
  volume        = {103},
  issn          = {1361-8415},
  url           = {http://dx.doi.org/10.1016/j.media.2025.103577},
  doi           = {10.1016/j.media.2025.103577},
  journal       = {Medical Image Analysis},
  publisher     = {Elsevier BV},
  author        = {Jena, Rohit and Chaudhari, Pratik and Gee, James C.},
  year          = {2025},
  month         = jul,
  pages         = {103577}
}
@article{undefreg,
  author        = {Ma, Yingjun and Niu, Dongmei and Zhang, Jinshuo and Zhao, Xiuyang and Yang, Bo and Zhang, Caiming},
  title         = {Unsupervised deformable image registration network for 3D medical images},
  year          = {2022},
  issue_date    = {Jan 2022},
  publisher     = {Kluwer Academic Publishers},
  address       = {USA},
  volume        = {52},
  number        = {1},
  issn          = {0924-669X},
  url           = {https://doi.org/10.1007/s10489-021-02196-7},
  doi           = {10.1007/s10489-021-02196-7},
  abstract      = {Image registration aims to establish an active correspondence between a pair of images. Such correspondence is critical for many significant applications, such as image fusion, tumor growth monitoring, and atlas generation. In this study, we propose an unsupervised deformable image registration network (UDIR-Net) for 3D medical images. The proposed UDIR-Net is designed in an encoder-decoder architecture and directly estimates the complex deformation field between input pairwise images without any supervised information. In particular, we recalibrate the feature slice of each feature map that is propagated between the encoder and the decoder in accordance with the importance of each feature slice and the correlation between feature slices. This method enhances the representational power of feature maps. To achieve efficient and robust training, we design a novel hierarchical loss function that evaluates multiscale similarity loss between registered image pairs. The proposed UDIR-Net is tested on different public magnetic resonance image datasets of the human brain. Experimental results show that UDIR-Net exhibits competitive performance against several state-of-the-art methods.},
  journal       = {Applied Intelligence},
  month         = jan,
  pages         = {766–779},
  numpages      = {14},
  keywords      = {Image registration, Convolutional neural network, Unsupervised learning, Brain MR images}
}
@article{retreggood,
  title         = {Retinal image registration as a tool for supporting clinical applications},
  journal       = {Computer Methods and Programs in Biomedicine},
  volume        = {199},
  pages         = {105900},
  year          = {2021},
  issn          = {0169-2607},
  doi           = {https://doi.org/10.1016/j.cmpb.2020.105900},
  url           = {https://www.sciencedirect.com/science/article/pii/S0169260720317338},
  author        = {Carlos Hernandez-Matas and Xenophon Zabulis and Antonis A. Argyros},
  keywords      = {Retinal image registration, Medical imaging, Shape estimation, Mosaicing, Superresolution},
  abstract      = {Background and Objective: The study of small vessels allows for the analysis and diagnosis of diseases with strong vasculopathy. This type of vessels can be observed non-invasively in the retina via fundoscopy. The analysis of these vessels can be facilitated by applications built upon Retinal Image Registration (RIR), such as mosaicing, Super Resolution (SR) or eye shape estimation. RIR is challenging due to possible changes in the retina across time, the utilization of diverse acquisition devices with varying properties, or the curved shape of the retina. Methods: We employ the Retinal Image Registration through Eye Modelling and Pose Estimation (REMPE) framework, which simultaneously estimates the cameras' relative poses, as well as eye shape and orientation to develop RIR applications and to study their effectiveness. Results: We assess quantitatively the suitability of the REMPE framework towards achieving SR and eye shape estimation. Additionally, we provide indicative results demonstrating qualitatively its usefulness in the context of longitudinal studies, mosaicing, and multiple image registration. Besides the improvement over registration accuracy, demonstrated via registration applications, the most important novelty presented in this work is the eye shape estimation and the generation of 3D point meshes. This has the potential for allowing clinicians to perform measurements on 3D representations of the eye, instead of doing so in 2D images that contain distortions induced because of the projection on the image space. Conclusions: RIR is very effective in supporting applications such as SR, eye shape estimation, longitudinal studies, mosaicing and multiple image registration. Its improved registration accuracy compared to the state of the art translates directly in improved performance when supporting the aforementioned applications.}
}
@article{rempe,
  author        = {C. {Hernandez-Matas} and X. {Zabulis} and A. {Argyros}},
  journal       = {IEEE Journal of Biomedical and Health Informatics},
  title         = {REMPE: Registration of Retinal Images through Eye Modelling and Pose Estimation},
  year          = {2020},
  volume        = {},
  number        = {},
  pages         = {},
  doi           = {10.1109/JBHI.2020.2984483}
}
@inproceedings{pso,
  author        = {Kennedy, J. and Eberhart, R.},
  booktitle     = {Proceedings of ICNN'95 - International Conference on Neural Networks},
  title         = {Particle swarm optimization},
  year          = {1995},
  volume        = {4},
  number        = {},
  pages         = {1942--1948 vol.4},
  keywords      = {Particle swarm optimization;Birds;Educational institutions;Marine animals;Testing;Humans;Genetic algorithms;Optimization methods;Artificial neural networks;Performance evaluation},
  doi           = {10.1109/ICNN.1995.488968}
}
@article{GDB-ICP2,
  author        = {Yang, Gehua and Stewart, Charles V. and Sofka, Michal and Tsai, Chia-Ling},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title         = {Registration of Challenging Image Pairs: Initialization, Estimation, and Decision},
  year          = {2007},
  volume        = {29},
  number        = {11},
  pages         = {1973--1989},
  keywords      = {Layout;Lighting;Iterative algorithms;Change detection algorithms;Biomedical imaging;Parameter estimation;Testing;Iterative closest point algorithm;Stability criteria;Feature extraction;Image registration;feature extraction;iterative closest point;radial lens distortion;decision criteria;keypoint},
  doi           = {10.1109/TPAMI.2007.1116}
}
@article{GDB-ICP,
  author        = {Stewart, Charles and Tsai, Chia-Ling and Roysam, Badrinath},
  year          = {2003},
  month         = {12},
  pages         = {1379--94},
  title         = {The Dual-Bootstrap Iterative Closest Point Algorithm with Application to Retinal Image Registration},
  volume        = {22},
  journal       = {IEEE transactions on medical imaging},
  doi           = {10.1109/TMI.2003.819276}
}
@article{GDB-ICP2,
  title         = {The dual-bootstrap iterative closest point algorithm with application to retinal image registration},
  author        = {Charles V. Stewart and Chia-Ling Tsai and Badrinath Roysam},
  journal       = {IEEE Transactions on Medical Imaging},
  year          = {2003},
  volume        = {22},
  pages         = {1379--1394},
  url           = {https://api.semanticscholar.org/CorpusID:1415570}
}
@inproceedings{H-M16,
  author        = {Hernandez-Matas, Carlos and Zabulis, Xenophon and Argyros, Antonis A.},
  booktitle     = {2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  title         = {Retinal image registration through simultaneous camera pose and eye shape estimation},
  year          = {2016},
  volume        = {},
  number        = {},
  pages         = {3247--3251},
  keywords      = {Cameras;Three-dimensional displays;Retina;Ellipsoids;Shape;Image registration;Mathematical model},
  doi           = {10.1109/EMBC.2016.7591421}
}
@article{ilginis2014ophthalmic,
  title         = {Ophthalmic imaging.},
  author        = {Ilginis, Tomas and Clarke, Jonathan and Patel, Praveen J},
  journal       = {British medical bulletin},
  volume        = {111},
  number        = {1},
  year          = {2014}
}
@article{visionyojo,
  author        = {Ferreruela, Rafael},
  title         = {La visi\'{o}n y el ojo},
  year          = {2007},
  journal       = {Apunts Educaci\'{o}n F\'{\i}sica y Deportes},
  keywords      = {Ojo;  Estructuras oculares;  Par\'{a}metros.; Eye;  Ocular structures;  Visual parameters.},
  issn          = {1577-4015},
  language      = {Espa\~{n}ol},
  url           = {https://www.redalyc.org/articulo.oa?id=551656954002},
  abstract      = {En este art\'{\i}culo se hace un repaso de todas las estructuras anat\'{o}micas del ojo, tanto las internas como las externas. Todas ellas ayudan a conseguir el objetivo final para el que est\'{a}n dise\~{n}adas, y as\'{\i} enfocar el est\'{\i}mulo luminoso que llega desde el exterior para poder ver correctamente. Finalmente es el cerebro el que ``ve'', pues es el que interpreta las im\'{a}genes. Tambi\'{e}n se hace un repaso a las principales pruebas que se utilizan en la consulta diaria para evaluar el estado de salud ocular de un individuo, con especial \'{e}nfasis en aquellas que pueden tener un papel m\'{a}s relevante en la visi\'{o}n durante la pr\'{a}ctica deportiva. visuales.}
}
@misc{sivaraman2024retinaregnetzeroshotapproachretinal,
  title         = {RetinaRegNet: A Zero-Shot Approach for Retinal Image Registration},
  author        = {Vishal Balaji Sivaraman and Muhammad Imran and Qingyue Wei and Preethika Muralidharan and Michelle R. Tamplin and Isabella M . Grumbach and Randy H. Kardon and Jui-Kai Wang and Yuyin Zhou and Wei Shao},
  year          = {2024},
  eprint        = {2404.16017},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2404.16017}
}
@article{sift,
  title         = {Distinctive Image Features from Scale-Invariant Keypoints},
  author        = {David G. Lowe},
  journal       = {International Journal of Computer Vision},
  year          = {2004},
  volume        = {60},
  pages         = {91--110},
  url           = {https://api.semanticscholar.org/CorpusID:174065}
}
@article{ur-sift,
  author        = {Ghassabi, Z.R. and Shanbezadeh, Jamshid and Sedaghat, Amin and Fatemizadeh, Emad},
  year          = {2013},
  month         = {12},
  pages         = {1--16},
  title         = {An efficient approach for robust multimodal retinal image registration based on UR-SIFT features and PIIFD descriptors},
  volume        = {1},
  journal       = {EURASIP Journal on Image and Video Processing},
  doi           = {10.1186/1687-5281-2013-25}
}
@article{MFSP,
  author        = {Tang, Haolin and Pan, Anning and Yang, Yang and Yang, Kun and Luo, Yi and Zhang, Su and Ong, Sim},
  year          = {2018},
  month         = {02},
  pages         = {240--249},
  title         = {Retinal Image Registration Based on Robust Non-Rigid Point Matching Method},
  volume        = {8},
  journal       = {Journal of Medical Imaging and Health Informatics},
  doi           = {10.1166/jmihi.2018.2283}
}
@article{GMM,
  author        = {Chengyin Liu and Jiayi Ma and Yong Ma and Jun Huang},
  journal       = {J. Opt. Soc. Am. A},
  keywords      = {Digital image processing; Medical and biological imaging; Algorithms ; Pattern recognition, image transforms ; Clinical applications; Computational imaging; Image metrics; Image registration; Optical imaging; Pattern recognition},
  number        = {7},
  pages         = {1267--1276},
  publisher     = {Optica Publishing Group},
  title         = {Retinal image registration via feature-guided Gaussian mixture model},
  volume        = {33},
  month         = {Jul},
  year          = {2016},
  url           = {https://opg.optica.org/josaa/abstract.cfm?URI=josaa-33-7-1267},
  doi           = {10.1364/JOSAA.33.001267},
  abstract      = {Registration of retinal images taken at different times, from different perspectives, or with different modalities is a critical prerequisite for the diagnoses and treatments of various eye diseases. This problem can be formulated as registration of two sets of sparse feature points extracted from the given images, and it is typically solved by first creating a set of putative correspondences and then removing the false matches as well as estimating the spatial transformation between the image pairs or solved by estimating the correspondence and transformation jointly involving an iteration process. However, the former strategy suffers from missing true correspondences, and the latter strategy does not make full use of local appearance information, which may be problematic for low-quality retinal images due to a lack of reliable features. In this paper, we propose a feature-guided Gaussian mixture model (GMM) to address these issues. We formulate point registration as the estimation of a feature-guided mixture of densities: A GMM is fitted to one point set, such that both the centers and local features of the Gaussian densities are constrained to coincide with the other point set. The problem is solved under a unified maximum-likelihood framework together with an iterative expectation-maximization algorithm initialized by the confident feature correspondences, where the image transformation is modeled by an affine function. Extensive experiments on various retinal images show the robustness of our approach, which consistently outperforms other state-of-the-art methods, especially when the data is badly degraded.}
}
@article{coin,
  author        = {Emilien Dupont and Hrushikesh Loya and Milad Alizadeh and Adam Golinski and Yee Whye Teh and Arnaud Doucet},
  title         = {{COIN++:} Data Agnostic Neural Compression},
  journal       = {CoRR},
  volume        = {abs/2201.12904},
  year          = {2022},
  url           = {https://arxiv.org/abs/2201.12904},
  eprinttype    = {arXiv},
  eprint        = {2201.12904},
  timestamp     = {Wed, 02 Feb 2022 15:00:01 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2201-12904.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}
@article{TPS,
  author        = {Bookstein, F.L.},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title         = {Principal warps: thin-plate splines and the decomposition of deformations},
  year          = {1989},
  volume        = {11},
  number        = {6},
  pages         = {567--585},
  keywords      = {Integral equations;Shape;Steel;Interpolation;Image analysis;Biomedical imaging;Algebra;Biological system modeling;Deformable models;Functional analysis},
  doi           = {10.1109/34.24792}
}
@article{surf,
  title         = {Speeded-Up Robust Features (SURF)},
  journal       = {Computer Vision and Image Understanding},
  volume        = {110},
  number        = {3},
  pages         = {346--359},
  year          = {2008},
  note          = {Similarity Matching in Computer Vision and Multimedia},
  issn          = {1077-3142},
  doi           = {https://doi.org/10.1016/j.cviu.2007.09.014},
  url           = {https://www.sciencedirect.com/science/article/pii/S1077314207001555},
  author        = {Herbert Bay and Andreas Ess and Tinne Tuytelaars and Luc {Van Gool}},
  keywords      = {Interest points, Local features, Feature description, Camera calibration, Object recognition},
  abstract      = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision.}
}
@article{piifd,
  author        = {Chen, Jian and Tian, Jie and Lee, Noah and Zheng, Jian and Smith, R. Theodore and Laine, Andrew F.},
  journal       = {IEEE Transactions on Biomedical Engineering},
  title         = {A Partial Intensity Invariant Feature Descriptor for Multimodal Retinal Image Registration},
  year          = {2010},
  volume        = {57},
  number        = {7},
  pages         = {1707--1718},
  keywords      = {Retina;Image registration;Bifurcation;Automation;Biomedical engineering;Robustness;Content addressable storage;Laboratories;Degenerative diseases;Automatic control;Harris detector;local feature;multimodal registration;partial intensity invariance;retinal images},
  doi           = {10.1109/TBME.2010.2042169}
}
@inproceedings{Harris1988ACC,
  title         = {A Combined Corner and Edge Detector},
  author        = {Christopher G. Harris and M. J. Stephens},
  booktitle     = {Alvey Vision Conference},
  year          = {1988},
  url           = {https://api.semanticscholar.org/CorpusID:1694378}
}
@inproceedings{BBF,
  author        = {Beis, J.S. and Lowe, D.G.},
  booktitle     = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  title         = {Shape indexing using approximate nearest-neighbour search in high-dimensional spaces},
  year          = {1997},
  volume        = {},
  number        = {},
  pages         = {1000--1006},
  keywords      = {Shape;Indexing;Spatial databases;Object detection;Image databases;Neural networks;Tree data structures;Computer science;Computer vision;Layout},
  doi           = {10.1109/CVPR.1997.609451}
}
@inproceedings{brisk,
  author        = {Leutenegger, Stefan and Chli, Margarita and Siegwart, Roland Y.},
  booktitle     = {2011 International Conference on Computer Vision},
  title         = {BRISK: Binary Robust invariant scalable keypoints},
  year          = {2011},
  volume        = {},
  number        = {},
  pages         = {2548--2555},
  keywords      = {Detectors;Boats;Brightness;Robustness;Kernel;Feature extraction;Complexity theory},
  doi           = {10.1109/ICCV.2011.6126542}
}
@inproceedings{freakkeypoint,
  author        = {Alahi, Alexandre and Ortiz, Raphael and Vandergheynst, Pierre},
  booktitle     = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
  title         = {FREAK: Fast Retina Keypoint},
  year          = {2012},
  volume        = {},
  number        = {},
  pages         = {510--517},
  keywords      = {Retina;Robustness;Humans;Detectors;Vectors;Kernel;Noise},
  doi           = {10.1109/CVPR.2012.6247715}
}
@article{ransac,
  author        = {Fischler, Martin A. and Bolles, Robert C.},
  title         = {Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
  year          = {1981},
  issue_date    = {June 1981},
  publisher     = {Association for Computing Machinery},
  address       = {New York, NY, USA},
  volume        = {24},
  number        = {6},
  issn          = {0001-0782},
  url           = {https://doi.org/10.1145/358669.358692},
  doi           = {10.1145/358669.358692},
  abstract      = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
  journal       = {Commun. ACM},
  month         = jun,
  pages         = {381–395},
  numpages      = {15},
  keywords      = {scene analysis, model fitting, location determination, image matching, camera calibration, automated cartography}
}
@article{flann,
  author        = {Muja, Marius and Lowe, David G.},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title         = {Scalable Nearest Neighbor Algorithms for High Dimensional Data},
  year          = {2014},
  volume        = {36},
  number        = {11},
  pages         = {2227--2240},
  keywords      = {Approximation algorithms;Clustering algorithms;Vegetation;Partitioning algorithms;Approximation methods;Machine learning algorithms;Computer vision;Nearest neighbor search;big data;approximate search;algorithm configuration},
  doi           = {10.1109/TPAMI.2014.2321376}
}
@article{ants,
  title         = {The {ANTsX} ecosystem for quantitative biological and medical imaging},
  volume        = {11},
  issn          = {2045-2322},
  url           = {https://doi.org/10.1038/s41598-021-87564-6},
  doi           = {10.1038/s41598-021-87564-6},
  abstract      = {The Advanced Normalizations Tools ecosystem, known as ANTsX, consists of multiple open-source software libraries which house top-performing algorithms used worldwide by scientific and research communities for processing and analyzing biological and medical imaging data. The base software library, ANTs, is built upon, and contributes to, the NIH-sponsored Insight Toolkit. Founded in 2008 with the highly regarded Symmetric Normalization image registration framework, the ANTs library has since grown to include additional functionality. Recent enhancements include statistical, visualization, and deep learning capabilities through interfacing with both the R statistical project (ANTsR) and Python (ANTsPy). Additionally, the corresponding deep learning extensions ANTsRNet and ANTsPyNet (built on the popular TensorFlow/Keras libraries) contain several popular network architectures and trained models for specific applications. One such comprehensive application is a deep learning analog for generating cortical thickness data from structural T1-weighted brain MRI, both cross-sectionally and longitudinally. These pipelines significantly improve computational efficiency and provide comparable-to-superior accuracy over multiple criteria relative to the existing ANTs workflows and simultaneously illustrate the importance of the comprehensive ANTsX approach as a framework for medical image analysis.},
  number        = {1},
  journal       = {Scientific Reports},
  author        = {Tustison, Nicholas J. and Cook, Philip A. and Holbrook, Andrew J. and Johnson, Hans J. and Muschelli, John and Devenyi, Gabriel A. and Duda, Jeffrey T. and Das, Sandhitsu R. and Cullen, Nicholas C. and Gillen, Daniel L. and Yassa, Michael A. and Stone, James R. and Gee, James C. and Avants, Brian B.},
  month         = apr,
  year          = {2021},
  pages         = {9068}
}
@article{elastix,
  title         = {elastix: A Toolbox for Intensity-Based Medical Image Registration},
  author        = {Stefan Klein and Marius Staring and Keelin Murphy and Max A. Viergever and Josien P. W. Pluim},
  journal       = {IEEE Transactions on Medical Imaging},
  year          = {2010},
  volume        = {29},
  pages         = {196--205},
  url           = {https://api.semanticscholar.org/CorpusID:15850341}
}
@article{simpleitk,
  author        = {Lowekamp, Bradley C. and Chen, David T. and Ibanez, Luis  and Blezek, Daniel},
  title         = {The Design of SimpleITK},
  journal       = {Frontiers in Neuroinformatics},
  volume        = {7},
  year          = {2013},
  url           = {https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2013.00045},
  doi           = {10.3389/fninf.2013.00045},
  issn          = {1662-5196},
  abstract      = {<p>SimpleITK is a new interface to the Insight Segmentation and Registration Toolkit (ITK) designed to facilitate rapid prototyping, education and scientific activities via high level programming languages. ITK is a templated C++ library of image processing algorithms and frameworks for biomedical and other applications, and it was designed to be generic, flexible and extensible. Initially, ITK provided a direct wrapping interface to languages such as Python and Tcl through the WrapITK system. Unlike WrapITK, which exposed ITK's complex templated interface, SimpleITK was designed to provide an easy to use and simplified interface to ITK's algorithms. It includes procedural methods, hides ITK's demand driven pipeline, and provides a template-less layer. Also SimpleITK provides practical conveniences such as binary distribution packages and overloaded operators. Our user-friendly design goals dictated a departure from the direct interface wrapping approach of WrapITK, toward a new facade class structure that only exposes the required functionality, hiding ITK's extensive template use. Internally SimpleITK utilizes a manual description of each filter with code-generation and advanced C++ meta-programming to provide the higher-level interface, bringing the capabilities of ITK to a wider audience. SimpleITK is licensed as open source software library under the Apache License Version 2.0 and more information about downloading it can be found at <ext-link ext-link-type="uri" xlink:href="http://www.simpleitk.org" xmlns:xlink="http://www.w3.org/1999/xlink">http://www.simpleitk.org</ext-link>.</p>}
}
@article{deeplernreview3dreg,
  author        = {Xiao, Haonan and Teng, Xinzhi and Liu, Chenyang and Li, Tian and Ren, Ge and Yang, Ruijie and Shen, Dinggang and Cai, Jing},
  year          = {2021},
  month         = {12},
  pages         = {},
  title         = {A review of deep learning-based three-dimensional medical image registration methods},
  volume        = {11},
  journal       = {Quantitative Imaging in Medicine and Surgery},
  doi           = {10.21037/qims-21-175}
}
@misc{scopus,
  title         = {Scopus},
  howpublished  = {Retrieved from https://www.scopus.com/},
  note          = {Accessed on 10-12-2024},
  year          = {2024}
}
@article{medicalimageanalysis,
  author        = {Altaf, Fouzia and Islam, Syed M. S. and Akhtar, Naveed and Janjua, Naeem Khalid},
  journal       = {IEEE Access},
  title         = {Going Deep in Medical Image Analysis: Concepts, Methods, Challenges, and Future Directions},
  year          = {2019},
  volume        = {7},
  number        = {},
  pages         = {99540--99572},
  keywords      = {Biomedical imaging;Deep learning;Computational modeling;Task analysis;Computer vision;Data models;Deep learning;medical imaging;artificial neural networks;survey;tutorial;data sets},
  doi           = {10.1109/ACCESS.2019.2929365}
}
@misc{mahapatra2019ganbasedmedicalimage,
  title         = {GAN Based Medical Image Registration},
  author        = {Dwarikanath Mahapatra},
  year          = {2019},
  eprint        = {1805.02369},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1805.02369}
}
@misc{defregcnn,
  author        = {Lafarge, Maxime and Moeskops, Pim and Veta, Mitko and Pluim, Josien and Eppenhof, Koen},
  year          = {2018},
  month         = {03},
  pages         = {27},
  title         = {Deformable image registration using convolutional neural networks},
  doi           = {10.1117/12.2292443}
}
@article{gan2,
  author        = {Zheng, Yuanjie and Sui, Xiaodan and Jiang, Yanyun and Che, Tongtong and Zhang, Shaoting and Yang, Jie and Li, Hongsheng},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title         = {SymReg-GAN: Symmetric Image Registration With Generative Adversarial Networks},
  year          = {2022},
  volume        = {44},
  number        = {9},
  pages         = {5631--5646},
  keywords      = {Image registration;Generative adversarial networks;Generators;Estimation;Training;Magnetic resonance imaging;Image resolution;Symmetric registration;generative adversarial networks;multimodal image registration},
  doi           = {10.1109/TPAMI.2021.3083543}
}
@misc{shen2023nerpimplicitneuralrepresentation,
  title         = {NeRP: Implicit Neural Representation Learning with Prior Embedding for Sparsely Sampled Image Reconstruction},
  author        = {Liyue Shen and John Pauly and Lei Xing},
  year          = {2023},
  eprint        = {2108.10991},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2108.10991}
}
@misc{rahaman2019spectralbiasneuralnetworks,
  title         = {On the Spectral Bias of Neural Networks},
  author        = {Nasim Rahaman and Aristide Baratin and Devansh Arpit and Felix Draxler and Min Lin and Fred A. Hamprecht and Yoshua Bengio and Aaron Courville},
  year          = {2019},
  eprint        = {1806.08734},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  url           = {https://arxiv.org/abs/1806.08734}
}
@inproceedings{inrrobots,
  author        = {Schmidt, Adam and Mohareri, Omid and DiMaio, Simon and Salcudean, Septimiu E.},
  booktitle     = {2022 International Conference on Robotics and Automation (ICRA)},
  title         = {Fast Graph Refinement and Implicit Neural Representation for Tissue Tracking},
  year          = {2022},
  volume        = {},
  number        = {},
  pages         = {1281--1288},
  keywords      = {Deformable models;Interpolation;Image resolution;Automation;Tracking;Force;Surgery},
  doi           = {10.1109/ICRA46639.2022.9811742}
}
@inproceedings{teleoperatdrob,
  author        = {Zhang, Heng and Zhu, Lifeng and Shen, Jiangwei and Song, Aiguo},
  booktitle     = {2023 IEEE International Conference on Robotics and Automation (ICRA)},
  title         = {Implicit Neural Field Guidance for Teleoperated Robot-assisted Surgery},
  year          = {2023},
  volume        = {},
  number        = {},
  pages         = {6866--6872},
  keywords      = {Training;Medical robotics;Neural networks;Surgery;Phantoms;Mouth;Trajectory},
  doi           = {10.1109/ICRA48891.2023.10160475}
}
@misc{yu2024neuraltrajectorymodelimplicit,
  title         = {Neural Trajectory Model: Implicit Neural Trajectory Representation for Trajectories Generation},
  author        = {Zihan Yu and Yuqing Tang},
  year          = {2024},
  eprint        = {2402.01254},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/2402.01254}
}
@misc{liu2024progressiveretinalimageregistration,
      title={Progressive Retinal Image Registration via Global and Local Deformable Transformations}, 
      author={Yepeng Liu and Baosheng Yu and Tian Chen and Yuliang Gu and Bo Du and Yongchao Xu and Jun Cheng},
      year={2024},
      eprint={2409.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.01068}, 
}
@article{van_Harten_2024,
   title={Robust Deformable Image Registration Using Cycle-Consistent Implicit Representations},
   volume={43},
   ISSN={1558-254X},
   url={http://dx.doi.org/10.1109/TMI.2023.3321425},
   DOI={10.1109/tmi.2023.3321425},
   number={2},
   journal={IEEE Transactions on Medical Imaging},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={van Harten, Louis D. and Stoker, Jaap and Išgum, Ivana},
   year={2024},
   month=feb, pages={784–793}
 }


@inproceedings{trajectinr,
  author        = {Tenzer, Mark and Tung, Emmanuel and Rasheed, Zeeshan and Shafique, Khurram},
  booktitle     = {2024 25th IEEE International Conference on Mobile Data Management (MDM)},
  title         = {Generating Trajectories from Implicit Neural Models},
  year          = {2024},
  volume        = {},
  number        = {},
  pages         = {129--138},
  keywords      = {Training;Roads;Image edge detection;Stochastic processes;Routing;Prediction algorithms;Data models;trajectory generation;implicit neural representation;deep learning;unsupervised learning},
  doi           = {10.1109/MDM61037.2024.00036}
}
@misc{essakine2024standimplicitneuralrepresentations,
  title         = {Where Do We Stand with Implicit Neural Representations? A Technical and Performance Survey},
  author        = {Amer Essakine and Yanqi Cheng and Chun-Wun Cheng and Lipei Zhang and Zhongying Deng and Lei Zhu and Carola-Bibiane Sch\"{o}nlieb and Angelica I Aviles-Rivero},
  year          = {2024},
  eprint        = {2411.03688},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2411.03688}
}
@misc{ramasinghe2022periodicityunifyingframeworkactivations,
  title         = {Beyond Periodicity: Towards a Unifying Framework for Activations in Coordinate-MLPs},
  author        = {Sameera Ramasinghe and Simon Lucey},
  year          = {2022},
  eprint        = {2111.15135},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2111.15135}
}
@misc{saragadam2023wirewaveletimplicitneural,
  title         = {WIRE: Wavelet Implicit Neural Representations},
  author        = {Vishwanath Saragadam and Daniel LeJeune and Jasper Tan and Guha Balakrishnan and Ashok Veeraraghavan and Richard G. Baraniuk},
  year          = {2023},
  eprint        = {2301.05187},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2301.05187}
}
@misc{reddy2022multiimplicitneuralrepresentationfonts,
  title         = {A Multi-Implicit Neural Representation for Fonts},
  author        = {Pradyumna Reddy and Zhifei Zhang and Matthew Fisher and Hailin Jin and Zhaowen Wang and Niloy J. Mitra},
  year          = {2022},
  eprint        = {2106.06866},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2106.06866}
}
@misc{wu2021iremhighresolutionmagneticresonance,
  title         = {IREM: High-Resolution Magnetic Resonance (MR) Image Reconstruction via Implicit Neural Representation},
  author        = {Qing Wu and Yuwei Li and Lan Xu and Ruiming Feng and Hongjiang Wei and Qing Yang and Boliang Yu and Xiaozhao Liu and Jingyi Yu and Yuyao Zhang},
  year          = {2021},
  eprint        = {2106.15097},
  archiveprefix = {arXiv},
  primaryclass  = {eess.IV},
  url           = {https://arxiv.org/abs/2106.15097}
}
@article{zitova2003imageregistrationsurvey,
  title         = {Image registration methods: a survey},
  journal       = {Image and Vision Computing},
  volume        = {21},
  number        = {11},
  pages         = {977--1000},
  year          = {2003},
  issn          = {0262-8856},
  doi           = {https://doi.org/10.1016/S0262-8856(03)00137-9},
  url           = {https://www.sciencedirect.com/science/article/pii/S0262885603001379},
  author        = {Barbara Zitov\'{a} and Jan Flusser},
  keywords      = {Image registration, Feature detection, Feature matching, Mapping function, Resampling},
  abstract      = {This paper aims to present a review of recent as well as classic image registration methods. Image registration is the process of overlaying images (two or more) of the same scene taken at different times, from different viewpoints, and/or by different sensors. The registration geometrically align two images (the reference and sensed images). The reviewed approaches are classified according to their nature (area-based and feature-based) and according to four basic steps of image registration procedure: feature detection, feature matching, mapping function design, and image transformation and resampling. Main contributions, advantages, and drawbacks of the methods are mentioned in the paper. Problematic issues of image registration and outlook for the future research are discussed too. The major goal of the paper is to provide a comprehensive reference source for the researchers involved in image registration, regardless of particular application areas.}
}
@inproceedings{integrateintfeat,
  author        = {Papademetris, Xenophon and Jackowski, Andrea P. and Schultz, Robert T. and Staib, Lawrence H. and Duncan, James S.},
  editor        = {Barillot, Christian and Haynor, David R. and Hellier, Pierre},
  title         = {Integrated Intensity and Point-Feature Nonrigid Registration},
  booktitle     = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2004},
  year          = {2004},
  publisher     = {Springer Berlin Heidelberg},
  address       = {Berlin, Heidelberg},
  pages         = {763--770},
  abstract      = {In this work, we present a method for the integration of fea- ture and intensity information for non rigid registration. Our method is based on a free-form deformation model, and uses a normalized mu- tual information intensity similarity metric to match intensities and the robust point matching framework to estimate feature (point) correspon- dences. The intensity and feature components of the registration are posed in a single energy functional with associated weights. We com- pare our method to both point-based and intensity-based registrations. In particular, we evaluate registration accuracy as measured by point landmark distances and image intensity similarity on a set of seventeen normal subjects. These results suggest that the integration of intensity and point-based registration is highly effective in yielding more accurate registrations.},
  isbn          = {978-3-540-30135-6}
}
@misc{mescheder2019occupancynetworkslearning3d,
  title         = {Occupancy Networks: Learning 3D Reconstruction in Function Space},
  author        = {Lars Mescheder and Michael Oechsle and Michael Niemeyer and Sebastian Nowozin and Andreas Geiger},
  year          = {2019},
  eprint        = {1812.03828},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1812.03828}
}
@article{Balakrishnan_2019voxelmorph,
  title         = {VoxelMorph: A Learning Framework for Deformable Medical Image Registration},
  volume        = {38},
  issn          = {1558-254X},
  url           = {http://dx.doi.org/10.1109/TMI.2019.2897538},
  doi           = {10.1109/tmi.2019.2897538},
  number        = {8},
  journal       = {IEEE Transactions on Medical Imaging},
  publisher     = {Institute of Electrical and Electronics Engineers (IEEE)},
  author        = {Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R. and Guttag, John and Dalca, Adrian V.},
  year          = {2019},
  month         = aug,
  pages         = {1788–1800}
}
@misc{li2024neuralgraphicsprimitivesdeformable,
  title         = {Neural Graphics Primitives-based Deformable Image Registration for On-the-fly Motion Extraction},
  author        = {Xia Li and Fabian Zhang and Muheng Li and Damien Weber and Antony Lomax and Joachim Buhmann and Ye Zhang},
  year          = {2024},
  eprint        = {2402.05568},
  archiveprefix = {arXiv},
  primaryclass  = {physics.med-ph},
  url           = {https://arxiv.org/abs/2402.05568}
}
@misc{wang2022neuralrenderingstereo3d,
  title         = {Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in Robotic Surgery},
  author        = {Yuehao Wang and Yonghao Long and Siu Hin Fan and Qi Dou},
  year          = {2022},
  eprint        = {2206.15255},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2206.15255}
}
@misc{han2022diffeomorphicimageregistrationneural,
  title         = {Diffeomorphic Image Registration with Neural Velocity Field},
  author        = {Kun Han and Shanlin sun and Xiangyi Yan and Chenyu You and Hao Tang and Junayed Naushad and Haoyu Ma and Deying Kong and Xiaohui Xie},
  year          = {2022},
  eprint        = {2202.12498},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2202.12498}
}
@misc{velikova2024implicitneuralrepresentationsbreathingcompensated,
  title         = {Implicit Neural Representations for Breathing-compensated Volume Reconstruction in Robotic Ultrasound},
  author        = {Yordanka Velikova and Mohammad Farid Azampour and Walter Simson and Marco Esposito and Nassir Navab},
  year          = {2024},
  eprint        = {2311.04999},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/2311.04999}
}
@article{mueller2022instant,
  author        = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
  title         = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
  journal       = {ACM Trans. Graph.},
  issue_date    = {July 2022},
  volume        = {41},
  number        = {4},
  month         = jul,
  year          = {2022},
  pages         = {102:1--102:15},
  articleno     = {102},
  numpages      = {15},
  url           = {https://doi.org/10.1145/3528223.3530127},
  doi           = {10.1145/3528223.3530127},
  publisher     = {ACM},
  address       = {New York, NY, USA}
}
@misc{jacobsen2018irevnetdeepinvertiblenetworks,
  title         = {i-RevNet: Deep Invertible Networks},
  author        = {J\"{o}rn-Henrik Jacobsen and Arnold Smeulders and Edouard Oyallon},
  year          = {2018},
  eprint        = {1802.07088},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1802.07088}
}
@misc{sireninit,
  title         = {Simple initialization and parametrization of sinusoidal networks via their kernel bandwidth},
  author        = {Filipe de Avila Belbute-Peres and J. Zico Kolter},
  year          = {2022},
  eprint        = {2211.14503},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2211.14503}
}
@misc{ziyin2020neuralnetworksfaillearn,
  title         = {Neural Networks Fail to Learn Periodic Functions and How to Fix It},
  author        = {Liu Ziyin and Tilman Hartwig and Masahito Ueda},
  year          = {2020},
  eprint        = {2006.08195},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2006.08195}
}
@article{simmetric,
  author        = {Ming Li and Xin Chen and Xin Li and Bin Ma and Vitanyi, P.M.B.},
  journal       = {IEEE Transactions on Information Theory},
  title         = {The similarity metric},
  year          = {2004},
  volume        = {50},
  number        = {12},
  pages         = {3250--3264},
  keywords      = {Bioinformatics;Computer science;Genomics;Phylogeny;Robustness;History;Data mining;Internet;Biology computing;Plagiarism;Dissimilarity distance;Kolmogorov complexity;language tree construction;normalized compression distance;normalized information distance;parameter-free data mining;phylogeny in bioinformatics;universal similarity metric},
  doi           = {10.1109/TIT.2004.838101}
}
@article{Palubinskas02012017,
  author        = {Gintautas Palubinskas},
  title         = {Image similarity/distance measures: what is really behind MSE and SSIM?},
  journal       = {International Journal of Image and Data Fusion},
  volume        = {8},
  number        = {1},
  pages         = {32--53},
  year          = {2017},
  publisher     = {Taylor \& Francis},
  doi           = {10.1080/19479832.2016.1273259},
  url           = {https://doi.org/10.1080/19479832.2016.1273259},
  eprint        = {https://doi.org/10.1080/19479832.2016.1273259}
}
@misc{goyal2018accuratelargeminibatchsgd,
  title         = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
  author        = {Priya Goyal and Piotr Doll\'{a}r and Ross Girshick and Pieter Noordhuis and Lukasz Wesolowski and Aapo Kyrola and Andrew Tulloch and Yangqing Jia and Kaiming He},
  year          = {2018},
  eprint        = {1706.02677},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1706.02677}
}
@online{kexuefm,
  title         = {How does the learning rate change when Batch Size increases?},
  author        = {Su Jianlin},
  year          = {2024},
  month         = {Nov},
  url           = {https://kexue.fm/archives/10542}
}
